% sage_latex_guidelines.tex V1.20, 14 January 2017
% source: https://us.sagepub.com/en-us/nam/manuscript-submission-guidelines

\documentclass[ReviewAfour,sageh,times,12pt,doublespace]{./style/sagej}

% Template Preamble

\usepackage{moreverb,url}

\newcommand\BibTeX{{\rmfamily B\kern-.05em \textsc{i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\def\volumeyear{2016}

% Custom Preamble

% Important packages
\usepackage[
	colorlinks,
	bookmarksopen,
	bookmarksnumbered,
	citecolor=red,
	urlcolor=red]{hyperref} % automatic pdf outline and citations hyperlinks
\usepackage{placeins} 		% for FloatBarrier
\usepackage{amsmath, bm}
\usepackage[nolists, tablesfirst]{endfloat}	% To `separate' figures and tables from text if required
\usepackage{lineno} % for line numbering

% Paths (self-contained)
\newcommand{\pathBIB}{./bib}
\newcommand{\pathFIG}{./figures}
% Paths for work in progress versions
%\newcommand{\pathFIG}{../../imputeHD-comp/output/graphs} 	% pools from my R output folder
%\newcommand{\pathBIB}{../../statsLib}		% pools from my bibliography

% Macros
\newcommand{\norm}[1]{\left\lVert#1\right\rVert} % for l2 norm in equations
\setcitestyle{notesep={:}} % corrects \citep[e.g.][32]{key} ==>>   (e.g. Jones et al., 1990:32)

% Suppres longnamesfirst for citeations with more than 3 authors
\shortcites{burtonEtAl:2006,
			dengEtAl:2016,
			eekhoutEtAl:2014,
			eekhoutEtAl:2018,
			jamesEtAl:2013,
			shahEtAl:2014,
			vanBuurenEtAl:2006}

% Begin Manuscript
\begin{document}

% Manuscript details

\runninghead{Supplementary Material}

\title{High-dimensional imputation for the social sciences: a comparison of state-of-the-art methods}

\keywords{
	Supplementary Material
}

\maketitle

% Start line numbering here
\linenumbers

% Body
\section{Software and other computational details}

The code to run the simulation was written in the R statistical programming language (version 4.0.3). 
All experiments were run using a 2.6 GHz Intel Xeon(R) Gold 6126 processor, 523.78 GB of Memory. The
operating system was Windows Server 2012 R2.
Computations were run in parallel across 30 cores. 
Parallel computing was implemented using the R package \emph{parallel} and to ensure replicability 
of the findings seeds were set using the method by \cite{lecuyer:2002} implemented in the R package 
\emph{rlecuyer}.

\section{Review of use of MI in sociological journals}
We selected two high-impact sociological journals publishing quantitative research: American Journal of Sociology (AJS), and American Sociological Review (ASR).
This is the procedure we followed to review how article published in these two journals discussed missing values and imputation:
\begin{enumerate}
	\item Downloaded all the ``Research articles'' published in AJS and ASR between Jan 2017 and Jan 2022 (total of 170 + 219 articles)
			These excluded book reviews, and other types of non-research published material.
	\item Used the R `tm` package to extract the text from all of these articles.
	\item Selected the subset of articles where the words ``survey'', ``sample'', or ``questionnaire'' where used together with expressions typically used when quantitative analysis are performed (``significan*'' ``standard error'', ``p-value'', ``pvalue'', ``confidence interval*'').
	      The idea of this first screen was to exclude all theoretical papers that are only interested in commenting on theoretical arguments.
	\item Selected the subset of articles where one of the following expressions appeared: ``imputation'', ``single imputation'', ``multiple imputation''.
	\item Manual coding of the selected articles was performed to asses whether
	\begin{itemize}
		\item imputation was actually performed (sometimes the word imputation was used in these articles with a different meaning)
		\item multiple imputation or another form of imputation was performed (e.g. some article mentioned \emph{mean imputation})
		\item the number of imputations was reported
		\item the predictors used in the imputation models were clearly stated
	\end{itemize}
\end{enumerate}

\section{Convergence check details}

	Convergence of the imputation models was assessed in a preprocessing step.
	Before running the actual simulation studies, 10 datasets were generated according to each experimental set up.
	Missing values in each dataset were imputed by running 5 parallel imputation chains for each Multiple Imputation 
	method.
	Convergence was checked by plotting the mean of the imputed values for each variable in each stream, against the 
	iteration number.
	In each parallel run, all the MI algorithms run for 250 iterations.
	The imputation algorithms were considered to have converged after 50 iterations, after which 10 imputed data 
	sets were store and used for the subsequent standard complete data analysis and pooling.
	The only exception was BLasso, which required approximately 2000 iterations for convergence.

\section{Ridge penalty cross-validation details}
	The ridge penalty used in the BRidge algorithm was fixed across iterations .
	The value used in the simulation was determined by means of cross-validation in a pre-processing phase.
	The grid of possible values for the ridge penalty was $10^{-1}, 10^{-2}, \dots, 10^{-8}$.
	For each of 100 data repetitions, BRidge imputation was performed with each of the different penalty parameters
	and used to obtain 10 differently imputed datasets.
	For each data replication, the Fraction of Missing Information (FMI) \citep{savaleiRhemtulla:2012} associated with 
	each parameter in the analysis models of interest (see next section for details) was computed and then averaged across 
	repetitions.
	The mean of these average parameter FMIs was used as a composite measure of FMI associated with each ridge penalty
	value.
	Finally, the penalty value with the smallest composite FMI was selected.

\section{Additional Figures}

\subsection{Simulation Study: data from a multivariate normal distribution}

	In Figures \ref{fig:exp1bias} and \ref{fig:exp1cir}, we report the average, minimum, and maximum absolute PRB
	and CIC, obtained with the different missing data treatments, for each parameter type.
	As the GS estimates are used to define the reference "true" values of the parameters, the bias for this method
	is by definition 0 and it is omitted from the bias picture.
	These figures supplement the results reported in the main text by showing how the methods performed with a smaller
	proportion of missing cases ($pm = 0.1$).

\begin{figure}
\centering
\includegraphics{\pathFIG/exp1_bias_10revision.pdf}
\caption{\label{fig:exp1bias}
	Minimum, average, and maximum absolute percent relative bias ($\text{PRB}$) for the 6 item means, 6 variances,
	and 15 covariances in the simulation study.
	If not data points are reported for a method in a panel, all of its PRBs were larger than 50.
	}
\end{figure}

\begin{figure}
\centering
\includegraphics{\pathFIG/exp1_CI_10revision.pdf}
\caption{\label{fig:exp1cir}
	Minimum, average, and maximum CIC for the 6 item means, 6 variances, and 15 covariances in the simulation study.
	If not data points are reported for a method in a panel, all of its CICs were smaller than $0.80$.
	}
\end{figure}

\FloatBarrier

\subsection{Resampling Study}

	Figure \ref{fig:exp4bias_m1} reports the absolute values of the PRBs for the intercept and all the partial 
	regression coefficients in Model 1, under the different imputation methods, for both the low- and high-dimensional
	conditions.
	Figure \ref{fig:exp4cir_m1} reports CIC results in the same way.

\begin{figure}
	\centering
	\includegraphics{\pathFIG/exp4_imp_bias_allParms_m1.pdf}
	\caption{PRBs for all the model parameters in model 1. 
		The order of the bars is based on the absolute value of the PRBs.
		The values for the intercept, the focal regression coefficient, and the regression coefficient with which most 
		methods struggle (Largest Bias) are highlighted}
	\label{fig:exp4bias_m1}
\end{figure}

\begin{figure}
	\centering
	\includegraphics{\pathFIG/exp4_imp_ci_allParms_m1.pdf}
	\caption{CIC for all model parameter in model 1.
		Bars are sorted in by ascending value.
		The values for the intercept, the focal regression coefficient, and the regression coefficient with which most 
		methods struggle (Largest Bias) are highlighted}
	\label{fig:exp4cir_m1}
\end{figure}

\FloatBarrier

% Bibliography
\bibliographystyle{./style/asj}

\bibliography{
	\pathBIB/missingData/bibtex/papers,
	\pathBIB/missingData/bibtex/books,
	\pathBIB/missingData/bibtex/software,
	\pathBIB/bayesStats/bibtex/papers,
	\pathBIB/programming/bibtex/papers,
	\pathBIB/survey/bibtex/data,
	\pathBIB/survey/bibtex/studies,
	\pathBIB/statsLearn/bibtex/books,	
	\pathBIB/statsLearn/bibtex/papers,
	\pathBIB/statsLearn/bibtex/software
	}

\end{document}
